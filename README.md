# INFO8010 - MOZART - Generating Music with Transformers
As part of the INFO8010 - DEEP LEARNING course taught by Pr. Gilles Louppe at the University of LiÃ¨ge, we built a series of transformers aimed at generating music in MIDI format as a personal group project (3 students).  We provide here the different codes and also the results we were able to obtain.

To make our project memorable, we named it MOzART (Musical Orchestra z Artificial Rhapsody Transformer).

## Authors

This project was carried out by 3 people who contributed equally.
BRANDOIT Julien,
BODART Fanny,
CLARA Tom.

## Datasets

We have decided not to share the datasets used - even though we explain exactly how they were generated in our article - since they contain musical productions that are not free of copyright. We used these productions as part of an academic project, but we believe that artists deserve to receive the financial benefits and visibility associated with their work. Downloading or listening to their music through illegal platforms does not compensate the artists.

## What's in the repo ?

Here we provide the python codes we made from scratch, as well as the music files generated by the various models. Two folders are provided for each architecture. An unfiltered folder, in which we haven't made any selections or modifications to the productions, to give an idea of the proportion of 'pleasant to listen to' and 'less pleasant to listen to' productions. A filtered folder in which we've selected the productions we consider to be the most appealing. These are intended to spark interest in our project by showcasing high-quality productions.

We also provide the 'article' we have written for the project.

See [Architectures](Architectures/readme.md) for the different architectures implementations.

See [Results](Results/readme.md) for the results ! Plug in your headphones and let yourself be carried away by what MOZART was able to compose ðŸŽ¶ ðŸŽ¹...

## What have we learned ?
This academic project does not bring fundamental novelty to the field of music generation through the use of AI. It is an additional proof of concept of what the literature emphasizes.

From a personal perspective, this project has allowed us to better understand how to design architectures, the challenges of deep learning, and the importance of preprocessing and tokenization steps, which are often overlooked when starting with deep learning.

We had a lot of fun working on this project together, and it was a really great experience!

## Libraries

To run the code, you will need the following Python libraries:

1. **torch**: For tensor computation and deep learning with PyTorch.
   - Installation: `pip install torch`

2. **wandb**: For online experiment tracking and visualization.
   - Installation: `pip install wandb`

3. **matplotlib**: For data and result visualization.
   - Installation: `pip install matplotlib`

4. **numpy**: For array support and mathematical operations.
   - Installation: `pip install numpy`

5. **miditok**: A specific library for MIDI file tokenization.
   - Installation: `pip install miditok`
  
6. **mido**: A specific library to encode and decode MIDI file.
   - Installation : `pip install mido`

Make sure you have also installed any necessary dependencies for these libraries. Once you have installed these libraries, you should be able to run the code without any issues.
